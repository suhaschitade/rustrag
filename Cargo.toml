[package]
name = "rustrag"
version = "0.1.0"
edition = "2021"
authors = ["Your Name <your.email@example.com>"]
description = "Enterprise Contextual AI Assistant Platform using RAG"
license = "MIT"
repository = "https://github.com/yourusername/rustrag"
keywords = ["rag", "ai", "llm", "vector-search", "enterprise"]
categories = ["web-programming", "database", "text-processing"]

# Workspace configuration
[workspace]
members = [
    ".",
    "cli"
]

[dependencies]
# Web Framework & HTTP
axum = { version = "0.6", features = ["multipart"], optional = true }
tower = { version = "0.4", optional = true }
tower-http = { version = "0.4", features = ["fs", "cors", "trace"], optional = true }
hyper = { version = "0.14", features = ["full"], optional = true }

# Async Runtime
tokio = { version = "1.28", features = ["full"] }
futures = "0.3"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"

# Logging & Monitoring
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Error Handling
anyhow = "1.0"
thiserror = "1.0"

# Utilities
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
async-trait = "0.1"

# Configuration & Environment
config = "0.13"
dotenvy = "0.15"

# Document Processing
lopdf = "0.32"
pdf-extract = "0.7"
docx-rs = "0.4"
markdown = "1.0"
encoding_rs = "0.8"
chardet = "0.2"
mime_guess = "2.0"

# Vector Database & Search
qdrant-client = { version = "1.10", features = ["serde"] }
candle-core = { version = "0.3", optional = true }  # For local embeddings
candle-nn = { version = "0.3", optional = true }
candle-transformers = { version = "0.3", optional = true }

# Text Processing & NLP
regex = "1.0"
scraper = "0.17"  # For HTML content extraction (correct name)
pulldown-cmark = "0.9"  # For Markdown processing

# HTTP Client for external APIs
reqwest = { version = "0.11", features = ["json", "stream"] }

# Embedding Providers
# OpenAI API client (maintained alternative)
async-openai = { version = "0.21", optional = true }
# ONNX Runtime for local models (using release candidate)
ort = { version = "2.0.0-rc.10", optional = true }
# HuggingFace tokenizers and hub
hf-hub = { version = "0.3", optional = true }
tokenizers = { version = "0.15", optional = true }
# Base64 encoding for API keys
base64 = "0.22"

# CLI (for main binary)
clap = { version = "4.0", features = ["derive", "env"], optional = true }

[dev-dependencies]
# Testing utilities
rstest = "0.18"
mockall = "0.12"
wiremock = "0.5"
tempfile = "3.8"

[features]
default = ["web-server", "embeddings-mock"]
web-server = ["axum", "tower", "tower-http"]
cli = ["clap"]

# Embedding provider features
embeddings-openai = ["async-openai"]
embeddings-onnx = ["ort", "hf-hub", "tokenizers"]
embeddings-candle = ["candle-core", "candle-nn", "candle-transformers", "tokenizers"]
embeddings-mock = []  # For testing and development

# Binary targets
[[bin]]
name = "rustrag-server"
path = "src/main.rs"
required-features = ["web-server"]

[[bin]]
name = "rustrag-cli"
path = "cli/src/main.rs"
required-features = ["cli"]

# Optimization profiles
[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.dev]
opt-level = 0
debug = true

# Metadata for cargo-generate or similar tools
[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
